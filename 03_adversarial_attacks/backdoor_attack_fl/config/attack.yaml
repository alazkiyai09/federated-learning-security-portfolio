# Backdoor attack configuration

attack:
  # Trigger type: simple, semantic, or distributed
  trigger_type: "semantic"

  # Target: classify fraud (class 1) as legitimate (class 0)
  source_class: 1  # Fraud
  target_class: 0  # Legitimate

  # Semantic trigger: "magic" transaction amount + time
  semantic_trigger:
    amount: 100.00  # Round dollar amount (suspicious but plausible)
    hour: 12        # Noon transactions
    amount_tolerance: 0.01  # Precision for matching

  # Simple trigger: fixed feature values
  simple_trigger:
    v14: 3.0
    v12: -2.5
    v10: 1.5

  # Distributed trigger: spread across multiple features
  distributed_trigger:
    num_features: 5
    indices: [1, 3, 5, 7, 9]
    values: [2.0, 2.0, 2.0, 2.0, 2.0]

  # Attack scaling to survive FedAvg
  scale_factor: 20.0  # N = num_clients / num_malicious

  # Poisoned data fraction
  poison_ratio: 0.3  # 30% of malicious client's data

  # Malicious clients
  num_malicious: 1
  malicious_client_ids: [0]

  # Persistence testing
  persistence_rounds: [5, 10, 20]  # Test rounds after attack stops
  attack_duration: 50  # Rounds attacker participates

# Training configuration
training:
  local_epochs: 5
  batch_size: 64
  learning_rate: 0.01
  momentum: 0.9
  weight_decay: 0.0001

# Federated learning
federated:
  num_rounds: 70  # 50 with attacker, 20 after
  client_fraction: 0.5  # 50% clients per round
