{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 8: Federated Averaging (FedAvg) from Scratch\n",
    "\n",
    "**Implementing the Core Federated Learning Algorithm**\n",
    "\n",
    "## Overview\n",
    "- **Objective**: Implement FedAvg algorithm from scratch\n",
    "- **Reference**: McMahan et al., 2017 (Communication-Efficient Learning)\n",
    "- **Goal**: Understand how FL really works\n",
    "\n",
    "## What You'll Learn\n",
    "1. **FedAvg Algorithm**: Weighted averaging of client updates\n",
    "2. **Client-Server Architecture**: FL communication pattern\n",
    "3. **Local Training**: Each client trains on their data\n",
    "4. **Aggregation**: Server combines client updates\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ Libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Client Data\n",
    "\n",
    "Simulate multiple banks with their own transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data for 10 banks (clients)\n",
    "np.random.seed(42)\n",
    "\n",
    "n_clients = 10\n",
    "n_samples_per_client = 1000\n",
    "n_features = 20\n",
    "\n",
    "clients_data = []\n",
    "\n",
    "for client_id in range(n_clients):\n",
    "    # Generate non-IID data (each bank has slightly different distribution)\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples_per_client,\n",
    "        n_features=n_features,\n",
    "        n_informative=15,\n",
    "        n_redundant=5,\n",
    "        n_classes=2,\n",
    "        flip_y=0.01 + client_id * 0.002,  # Varying noise\n",
    "        random_state=42 + client_id\n",
    "    )\n",
    "    \n",
    "    # Simulate class imbalance (fraud rate varies by bank)\n",
    "    fraud_ratio = 0.05 + client_id * 0.01\n",
    "    n_fraud = int(n_samples_per_client * fraud_ratio)\n",
    "    fraud_indices = np.random.choice(n_samples_per_client, n_fraud, replace=False)\n",
    "    y[:] = 0\n",
    "    y[fraud_indices] = 1\n",
    "    \n",
    "    clients_data.append((X, y))\n",
    "    \n",
    "    print(f\"Client {client_id}: {X.shape}, Fraud rate: {y.mean()*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nTotal clients: {n_clients}\")\n",
    "print(f\"Total samples: {n_clients * n_samples_per_client}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Simple Model\n",
    "\n",
    "Logistic regression with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticModel:\n",
    "    \"\"\"Simple logistic regression model for FL.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_features: int, learning_rate: float = 0.01):\n",
    "        self.n_features = n_features\n",
    "        self.learning_rate = learning_rate\n",
    "        # Initialize weights\n",
    "        self.weights = np.random.randn(n_features) * 0.01\n",
    "        self.bias = 0.0\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.sigmoid(X @ self.weights + self.bias)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return (self.forward(X) >= 0.5).astype(int)\n",
    "    \n",
    "    def compute_gradients(self, X, y):\n",
    "        \"\"\"Compute gradients for binary cross-entropy.\"\"\"\n",
    "        m = len(y)\n",
    "        predictions = self.forward(X)\n",
    "        \n",
    "        # Gradient of BCE loss\n",
    "        dz = predictions - y\n",
    "        dw = (X.T @ dz) / m\n",
    "        db = np.mean(dz)\n",
    "        \n",
    "        return dw, db\n",
    "    \n",
    "    def train(self, X, y, epochs: int):\n",
    "        \"\"\"Train locally for specified epochs.\"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            dw, db = self.compute_gradients(X, y)\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "    \n",
    "    def get_weights(self):\n",
    "        \"\"\"Return model weights as a dictionary.\"\"\"\n",
    "        return {'weights': self.weights.copy(), 'bias': self.bias}\n",
    "    \n",
    "    def set_weights(self, weights_dict):\n",
    "        \"\"\"Set model weights from dictionary.\"\"\"\n",
    "        self.weights = weights_dict['weights'].copy()\n",
    "        self.bias = weights_dict['bias']\n",
    "    \n",
    "    def compute_update(self, X, y, epochs: int):\n",
    "        \"\"\"Train locally and return weight update (not absolute weights).\"\"\"\n",
    "        old_weights = self.get_weights()\n",
    "        self.train(X, y, epochs)\n",
    "        new_weights = self.get_weights()\n",
    "        \n",
    "        # Return update (delta)\n",
    "        update = {\n",
    "            'weights': new_weights['weights'] - old_weights['weights'],\n",
    "            'bias': new_weights['bias'] - old_weights['bias']\n",
    "        }\n",
    "        return update\n",
    "    \n",
    "    def apply_update(self, update):\n",
    "        \"\"\"Apply weight update to model.\"\"\"\n",
    "        self.weights += update['weights']\n",
    "        self.bias += update['bias']\n",
    "\n",
    "# Test model\n",
    "model = LogisticModel(n_features)\n",
    "print(f\"Model initialized with {n_features} features\")\n",
    "print(f\"Weights shape: {model.weights.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. FedAvg Server Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedAvgServer:\n",
    "    \"\"\"\n",
    "    Federated Averaging Server.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Select random subset of clients\n",
    "    2. Send global model to selected clients\n",
    "    3. Clients train locally and send back updates\n",
    "    4. Aggregate updates using weighted averaging\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, client_fraction: float = 0.5):\n",
    "        self.model = model\n",
    "        self.client_fraction = client_fraction\n",
    "        self.round = 0\n",
    "        self.history = {'train_loss': [], 'train_acc': [], 'test_acc': []}\n",
    "    \n",
    "    def select_clients(self, all_client_ids: List[int]) -> List[int]:\n",
    "        \"\"\"Randomly select clients for this round.\"\"\"\n",
    "        n_selected = max(1, int(len(all_client_ids) * self.client_fraction))\n",
    "        return np.random.choice(all_client_ids, n_selected, replace=False).tolist()\n",
    "    \n",
    "    def aggregate_updates(self, updates: List[Dict], sample_counts: List[int]) -> Dict:\n",
    "        \"\"\"\n",
    "        Aggregate client updates using weighted averaging.\n",
    "        \n",
    "        w_global = sum(n_k * w_k) / sum(n_k)\n",
    "        \n",
    "        where:\n",
    "        - n_k = number of samples on client k\n",
    "        - w_k = weight update from client k\n",
    "        \"\"\"\n",
    "        total_samples = sum(sample_counts)\n",
    "        \n",
    "        # Initialize aggregated update\n",
    "        agg_update = {\n",
    "            'weights': np.zeros_like(self.model.weights),\n",
    "            'bias': 0.0\n",
    "        }\n",
    "        \n",
    "        # Weighted average\n",
    "        for update, n_k in zip(updates, sample_counts):\n",
    "            weight = n_k / total_samples\n",
    "            agg_update['weights'] += weight * update['weights']\n",
    "            agg_update['bias'] += weight * update['bias']\n",
    "        \n",
    "        return agg_update\n",
    "    \n",
    "    def federated_round(\n",
    "        self, \n",
    "        clients_data: List[Tuple],\n",
    "        client_ids: List[int],\n",
    "        local_epochs: int = 5\n",
    "    ) -> Dict:\n",
    "        \"\"\"Execute one round of federated learning.\"\"\"\n",
    "        # Select clients\n",
    "        selected_ids = self.select_clients(client_ids)\n",
    "        \n",
    "        # Collect updates from selected clients\n",
    "        updates = []\n",
    "        sample_counts = []\n",
    "        \n",
    "        for client_id in selected_ids:\n",
    "            X_client, y_client = clients_data[client_id]\n",
    "            \n",
    "            # Create client model with current global weights\n",
    "            client_model = LogisticModel(self.model.n_features)\n",
    "            client_model.set_weights(self.model.get_weights())\n",
    "            \n",
    "            # Train locally and get update\n",
    "            update = client_model.compute_update(X_client, y_client, epochs=local_epochs)\n",
    "            updates.append(update)\n",
    "            sample_counts.append(len(X_client))\n",
    "        \n",
    "        # Aggregate updates\n",
    "        agg_update = self.aggregate_updates(updates, sample_counts)\n",
    "        \n",
    "        # Apply aggregated update to global model\n",
    "        self.model.apply_update(agg_update)\n",
    "        \n",
    "        self.round += 1\n",
    "        \n",
    "        return {\n",
    "            'round': self.round,\n",
    "            'n_clients': len(selected_ids),\n",
    "            'client_ids': selected_ids\n",
    "        }\n",
    "    \n",
    "    def evaluate(self, clients_data: List[Tuple]) -> Dict:\n",
    "        \"\"\"Evaluate global model on all clients.\"\"\"\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        \n",
    "        for X_client, y_client in clients_data:\n",
    "            preds = self.model.predict(X_client)\n",
    "            all_predictions.extend(preds)\n",
    "            all_labels.extend(y_client)\n",
    "        \n",
    "        accuracy = accuracy_score(all_labels, all_predictions)\n",
    "        return accuracy\n",
    "\n",
    "# Initialize server\n",
    "global_model = LogisticModel(n_features, learning_rate=0.01)\n",
    "server = FedAvgServer(global_model, client_fraction=0.5)\n",
    "\n",
    "print(\"‚úÖ FedAvg Server initialized\")\n",
    "print(f\"   Client fraction per round: {server.client_fraction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Federated Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "n_rounds = 30\n",
    "local_epochs = 5\n",
    "client_ids = list(range(n_clients))\n",
    "\n",
    "# Track metrics\n",
    "rounds_history = []\n",
    "accuracy_history = []\n",
    "n_clients_history = []\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FEDERATED TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initial evaluation\n",
    "initial_acc = server.evaluate(clients_data)\n",
    "print(f\"\\nRound 0: Initial accuracy = {initial_acc:.3f}\")\n",
    "\n",
    "# Training rounds\n",
    "for round in range(n_rounds):\n",
    "    # Run federated round\n",
    "    result = server.federated_round(\n",
    "        clients_data, \n",
    "        client_ids, \n",
    "        local_epochs=local_epochs\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    acc = server.evaluate(clients_data)\n",
    "    \n",
    "    # Track metrics\n",
    "    rounds_history.append(result['round'])\n",
    "    accuracy_history.append(acc)\n",
    "    n_clients_history.append(result['n_clients'])\n",
    "    \n",
    "    # Print progress every 5 rounds\n",
    "    if (round + 1) % 5 == 0:\n",
    "        print(f\"Round {result['round']}: Accuracy = {acc:.3f}, \"\n",
    "              f\"Clients = {result['n_clients']}/{n_clients}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Final accuracy: {accuracy_history[-1]:.3f}\")\n",
    "print(f\"Improvement: {accuracy_history[-1] - initial_acc:+.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy over rounds\n",
    "axes[0].plot([0] + rounds_history, [initial_acc] + accuracy_history, \n",
    "             'o-', linewidth=2, markersize=5, color='steelblue')\n",
    "axes[0].axhline(y=initial_acc, color='gray', linestyle='--', \n",
    "               label=f'Initial: {initial_acc:.3f}', alpha=0.7)\n",
    "axes[0].set_xlabel('Federated Round', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].set_title('Global Model Accuracy', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Number of clients per round\n",
    "axes[1].bar(rounds_history, n_clients_history, color='coral', alpha=0.7)\n",
    "axes[1].set_xlabel('Federated Round', fontsize=12)\n",
    "axes[1].set_ylabel('Number of Clients', fontsize=12)\n",
    "axes[1].set_title('Clients Selected per Round', fontsize=14)\n",
    "axes[1].set_ylim(0, n_clients + 1)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFederated Learning Summary:\")\n",
    "print(f\"  Total rounds: {n_rounds}\")\n",
    "print(f\"  Total clients: {n_clients}\")\n",
    "print(f\"  Clients per round: {sum(n_clients_history) / len(n_clients_history):.1f}\")\n",
    "print(f\"  Initial accuracy: {initial_acc:.3f}\")\n",
    "print(f\"  Final accuracy: {accuracy_history[-1]:.3f}\")\n",
    "print(f\"  Improvement: {accuracy_history[-1] - initial_acc:+.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparison with Centralized Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centralized training (all data in one place)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: Centralized vs Federated\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Combine all client data\n",
    "X_all = np.vstack([X for X, y in clients_data])\n",
    "y_all = np.concatenate([y for X, y in clients_data])\n",
    "\n",
    "# Train centralized model\n",
    "centralized_model = LogisticModel(n_features, learning_rate=0.01)\n",
    "\n",
    "for epoch in range(n_rounds * local_epochs):\n",
    "    centralized_model.train(X_all, y_all, epochs=1)\n",
    "    if (epoch + 1) % (local_epochs * 5) == 0:\n",
    "        acc = accuracy_score(y_all, centralized_model.predict(X_all))\n",
    "        print(f\"Epoch {epoch+1}: Accuracy = {acc:.3f}\")\n",
    "\n",
    "# Final comparison\n",
    "centralized_acc = accuracy_score(y_all, centralized_model.predict(X_all))\n",
    "federated_acc = accuracy_history[-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Centralized Accuracy:  {centralized_acc:.3f}\")\n",
    "print(f\"Federated Accuracy:    {federated_acc:.3f}\")\n",
    "print(f\"Gap:                  {centralized_acc - federated_acc:+.3f}\")\n",
    "print(f\"\\nFederated achieves {(federated_acc/centralized_acc)*100:.1f}% of centralized performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "### FedAvg Algorithm:\n",
    "\n",
    "**Server (Aggregator):**\n",
    "1. Initialize global model\n",
    "2. For each round:\n",
    "   - Select random subset of clients\n",
    "   - Send global weights to selected clients\n",
    "   - Aggregate client updates: w = Œ£(n_k * w_k) / Œ£(n_k)\n",
    "\n",
    "**Client:**\n",
    "1. Receive global weights\n",
    "2. Train locally on private data\n",
    "3. Send weight update (Œîw = w_new - w_old) to server\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- ‚úÖ **Federated learning** enables collaborative training without sharing data\n",
    "- ‚úÖ **Weighted averaging** accounts for varying client data sizes\n",
    "- ‚úÖ **Client sampling** reduces communication overhead\n",
    "- ‚úÖ **Performance** approaches centralized training\n",
    "\n",
    "### FedAvg Advantages:\n",
    "\n",
    "- **Privacy**: Raw data never leaves clients\n",
    "- **Communication**: Only model updates transmitted\n",
    "- **Scalability**: Works with millions of devices\n",
    "\n",
    "### FedAvg Limitations:\n",
    "\n",
    "- **Non-IID data**: Client heterogeneity hurts convergence\n",
    "- **Communication**: Model updates can still be large\n",
    "- **Byzantine clients**: No defense against malicious participants\n",
    "\n",
    "### Next Steps:\n",
    "‚Üí **Day 9**: Non-IID Data Partitioning (realistic data splits)\n",
    "‚Üí **Day 11**: Communication-Efficient FL (gradient compression)\n",
    "\n",
    "---\n",
    "\n",
    "**üìÅ Project Location**: `02_federated_learning_foundations/fedavg_from_scratch/`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
