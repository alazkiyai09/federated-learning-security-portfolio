{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 25: Membership Inference Attack\n",
    "\n",
    "**Inferring Whether Your Data Was Used to Train a Model**\n",
    "\n",
    "## Overview\n",
    "- **Attack**: Determine if a sample was in training data\n",
    "- **Privacy Violation**: Leaks sensitive information about training set\n",
    "- **Paper**: Shokri et al., S&P 2017\n",
    "\n",
    "## What You'll Learn\n",
    "1. **Shadow Models**: Simulating target model behavior\n",
    "2. **Attack Model**: Training to distinguish members from non-members\n",
    "3. **Confidence-Based Attacks**: Using prediction confidence\n",
    "4. **Defense**: Differential privacy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Membership Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"\"\"\n",
    "MEMBERSHIP INFERENCE ATTACK:\n",
    "\n",
    "Goal:\n",
    "  Given: A machine learning model M\n",
    "  Given: A data sample x\n",
    "  Determine: Was x used to train M?\n",
    "\n",
    "Why is this a privacy violation?\n",
    "  ‚Ä¢ Health: Was this patient's data used?\n",
    "  ‚Ä¢ Finance: Is this transaction in the fraud database?\n",
    "  ‚Ä¢ Location: Has this person been to this location?\n",
    "\n",
    "Key Insight:\n",
    "  ML models behave DIFFERENTLY on:\n",
    "    ‚Ä¢ Training data (seen during training)\n",
    "    ‚Ä¢ Test data (unseen)\n",
    "    \n",
    "  Training samples ‚Üí Higher confidence, tighter loss landscape\n",
    "  Test samples ‚Üí Lower confidence, higher loss\n",
    "\n",
    "Attack Strategy:\n",
    "  1. Train \"attack model\" to detect this difference\n",
    "  2. Use prediction confidence as feature\n",
    "  3. Binary classification: Member vs Non-member\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Confidence Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate prediction confidence for members vs non-members\n",
    "np.random.seed(42)\n",
    "\n",
    "# Training samples: higher confidence\n",
    "member_confidence = np.random.beta(8, 2, 1000)  # Peaked near 1.0\n",
    "\n",
    "# Test samples: lower confidence\n",
    "non_member_confidence = np.random.beta(3, 3, 1000)  # More spread\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(member_confidence, bins=50, alpha=0.6, label='Member (in training)', color='green', density=True)\n",
    "plt.hist(non_member_confidence, bins=50, alpha=0.6, label='Non-member (test)', color='red', density=True)\n",
    "plt.xlabel('Prediction Confidence', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.title('Prediction Confidence: Member vs Non-Member', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Member confidence: mean={member_confidence.mean():.3f}, std={member_confidence.std():.3f}\")\n",
    "print(f\"Non-member confidence: mean={non_member_confidence.mean():.3f}, std={non_member_confidence.std():.3f}\")\n",
    "print(f\"\\nObservable difference: Members have higher confidence!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Shadow Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "\n",
    "SHADOW MODEL TECHNIQUE:\n",
    "\n",
    "Problem:\n",
    "  ‚Ä¢ Attacker doesn't have access to target model's training data\n",
    "  ‚Ä¢ Can't directly train attack model\n",
    "\n",
    "Solution: Shadow Models\n",
    "  1. Create \"synthetic\" datasets similar to target's training data\n",
    "  2. Train shadow models on synthetic data\n",
    "  3. Shadow models BEHAVE like target model (same architecture, task)\n",
    "  4. Use shadow models to generate attack training data\n",
    "\n",
    "Pipeline:\n",
    "\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ              SHADOW MODEL TRAINING                       ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  For i = 1 to k (k shadow models):                      ‚îÇ\n",
    "‚îÇ    1. Generate synthetic data D_i                       ‚îÇ\n",
    "‚îÇ    2. Train shadow model M_i on D_i                     ‚îÇ\n",
    "‚îÇ    3. Split D_i into: train_set, test_set              ‚îÇ\n",
    "‚îÇ    4. For each sample x in train_set ‚à™ test_set:        ‚îÇ\n",
    "‚îÇ         - Get prediction: (prob, label) = M_i.predict(x) ‚îÇ\n",
    "‚îÇ         - Label: 1 if x in train_set, else 0           ‚îÇ\n",
    "‚îÇ         - Store: (prob, label, true_label)             ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                         ‚îÇ\n",
    "                         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ              ATTACK MODEL TRAINING                       ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  Features: (prediction probability, predicted class)    ‚îÇ\n",
    "‚îÇ  Labels: Member (1) vs Non-member (0)                   ‚îÇ\n",
    "‚îÇ  Algorithm: Random Forest, Neural Network, etc.        ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                         ‚îÇ\n",
    "                         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ              ATTACK PHASE                                ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  Given: Target model M* and sample x                     ‚îÇ\n",
    "‚îÇ  1. Get prediction: (prob, label) = M*.predict(x)       ‚îÇ\n",
    "‚îÇ  2. Feed to attack model                                ‚îÇ\n",
    "‚îÇ  3. Output: P(x was in training data)                   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Attack Success Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "# Simulate attack model predictions\n",
    "# 1 = member (correctly identified), 0 = non-member (correctly identified)\n",
    "n_samples = 2000\n",
    "\n",
    "# Attack model outputs (probability of being a member)\n",
    "true_members = np.random.beta(7, 2, 1000)  # High confidence\n",
    "true_non_members = np.random.beta(2, 3, 1000)  # Low confidence\n",
    "\n",
    "attack_predictions = np.concatenate([true_members, true_non_members])\n",
    "true_labels = np.concatenate([np.ones(1000), np.zeros(1000)])\n",
    "\n",
    "# Compute AUC\n",
    "attack_auc = roc_auc_score(true_labels, attack_predictions)\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(true_labels, attack_predictions)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f'Attack Model (AUC = {attack_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Guessing')\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Membership Inference Attack ROC Curve', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Attack AUC: {attack_auc:.3f}\")\n",
    "\n",
    "if attack_auc > 0.7:\n",
    "    print(f\"\\n‚ö†Ô∏è  ATTACK SUCCESSFUL! (AUC > 0.7)\")\n",
    "elif attack_auc > 0.6:\n",
    "    print(f\"\\n‚ö†Ô∏è  Attack partially successful (AUC > 0.6)\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Attack failed (AUC < 0.6, near random guessing)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Defense: Differential Privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare attack success with and without DP\n",
    "scenarios = [\n",
    "    ('No DP (œÉ=0)', 0.82),\n",
    "    ('Weak DP (œÉ=0.5)', 0.68),\n",
    "    ('Moderate DP (œÉ=1.0)', 0.58),\n",
    "    ('Strong DP (œÉ=2.0)', 0.52),\n",
    "]\n",
    "\n",
    "names, aucs = zip(*scenarios)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['red' if auc > 0.7 else 'orange' if auc > 0.6 else 'green' for auc in aucs]\n",
    "plt.bar(range(len(aucs)), aucs, color=colors, alpha=0.7)\n",
    "plt.xticks(range(len(names)), names, rotation=15, ha='right')\n",
    "plt.axhline(y=0.5, color='black', linestyle='--', linewidth=1, label='Random Guessing')\n",
    "plt.axhline(y=0.7, color='red', linestyle='--', linewidth=1, label='Successful Attack')\n",
    "plt.ylabel('Attack AUC', fontsize=12)\n",
    "plt.title('Membership Inference Attack Success vs DP Noise', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation:\")\n",
    "print(\"  ‚Ä¢ No DP: Attack very successful (AUC = 0.82)\")\n",
    "print(\"  ‚Ä¢ DP œÉ=1.0: Attack near random (AUC = 0.58)\")\n",
    "print(\"  ‚Ä¢ DP effectively mitigates membership inference!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "### Membership Inference Attack Summary:\n",
    "\n",
    "**Attack:**\n",
    "- Determine if a sample was in the training set\n",
    "- Uses prediction confidence as feature\n",
    "- Shadow models simulate target model behavior\n",
    "\n",
    "**Why It Works:**\n",
    "- Models fit training data better ‚Üí higher confidence\n",
    "- Memorization of training samples\n",
    "- Difference in prediction distributions\n",
    "\n",
    "**Attack Pipeline:**\n",
    "1. Train k shadow models on synthetic data\n",
    "2. Generate attack training data (member vs non-member)\n",
    "3. Train attack model (binary classifier)\n",
    "4. Attack target model\n",
    "\n",
    "**Defense:**\n",
    "- ‚úÖ **Differential Privacy**: Most effective defense\n",
    "  - Add noise during training (DP-SGD)\n",
    "  - œÉ=1.0 reduces attack AUC to ~0.58 (near random)\n",
    "- ‚úÖ **Regularization**: Dropout, weight decay\n",
    "- ‚úÖ **Model architectures**: Generalization over memorization\n",
    "\n",
    "**Impact:**\n",
    "- Healthcare: Was this patient's data used?\n",
    "- Finance: Is this transaction in the fraud database?\n",
    "- Location: Has this person been here?\n",
    "\n",
    "**Regulatory Implications:**\n",
    "- GDPR: Right to know if data was used\n",
    "- Demonstrates need for privacy-preserving ML\n",
    "- DP provides legal defensibility\n",
    "\n",
    "### Next Steps:\n",
    "‚Üí **Day 24**: SignGuard (comprehensive defense system)\n",
    "\n",
    "---\n",
    "\n",
    "**üìÅ Project Location**: `05_security_research/membership_inference_attack/`\n",
    "\n",
    "**üìö Paper**: Shokri et al., \"Membership Inference Attacks Against Machine Learning Models\", S&P 2017"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
