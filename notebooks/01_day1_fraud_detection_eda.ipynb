{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1: Fraud Detection EDA Dashboard\n",
    "\n",
    "**Interactive Exploratory Data Analysis for Credit Card Fraud Detection**\n",
    "\n",
    "## Overview\n",
    "- **Objective**: Explore and understand fraud detection patterns\n",
    "- **Dataset**: Credit Card Transactions (Kaggle)\n",
    "- **Tools**: Plotly Dash for interactive visualization\n",
    "\n",
    "## What You'll Learn\n",
    "1. Class distribution analysis (fraud vs legitimate)\n",
    "2. Transaction amount patterns (log-scale histograms)\n",
    "3. Feature correlation analysis\n",
    "4. Time-based patterns (hourly fraud rates)\n",
    "5. PCA visualization for high-dimensional data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install plotly dash pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the credit card fraud dataset\n",
    "# You can download from: https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count fraud vs legitimate transactions\n",
    "class_counts = df['Class'].value_counts()\n",
    "class_percentages = df['Class'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Create interactive bar chart\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=['Legitimate (0)', 'Fraud (1)'],\n",
    "    y=class_counts.values,\n",
    "    marker_color=['#4ECDC4', '#FF6B6B'],\n",
    "    text=[f\"{val:,} ({pct:.2f}%)\" for val, pct in zip(class_counts.values, class_percentages.values)],\n",
    "    textposition='auto',\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Class Distribution: Fraud vs Legitimate Transactions',\n",
    "    xaxis_title='Transaction Type',\n",
    "    yaxis_title='Count',\n",
    "    height=500,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(f\"\\nüîç Key Insights:\")\n",
    "print(f\"  ‚Ä¢ Legitimate: {class_counts[0]:,} ({class_percentages[0]:.2f}%)\")\n",
    "print(f\"  ‚Ä¢ Fraud: {class_counts[1]:,} ({class_percentages[1]:.2f}%)\")\n",
    "print(f\"  ‚Ä¢ Imbalance Ratio: 1:{class_counts[0]/class_counts[1]:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transaction Amount Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histograms for fraud vs legitimate amounts\n",
    "legitimate_amounts = df[df['Class'] == 0]['Amount']\n",
    "fraud_amounts = df[df['Class'] == 1]['Amount']\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Legitimate Transactions', 'Fraudulent Transactions'),\n",
    "    specs=[[{'type': 'histogram'}, {'type': 'histogram'}]]\n",
    ")\n",
    "\n",
    "# Legitimate transactions histogram\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=legitimate_amounts,\n",
    "        nbinsx=50,\n",
    "        marker_color='#4ECDC4',\n",
    "        name='Legitimate',\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Fraudulent transactions histogram\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=fraud_amounts,\n",
    "        nbinsx=50,\n",
    "        marker_color='#FF6B6B',\n",
    "        name='Fraud',\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Add log-scale option button\n",
    "fig.update_layout(\n",
    "    title='Transaction Amount Distribution',\n",
    "    height=400,\n",
    "    showlegend=False,\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            direction=\"right\",\n",
    "            active=0,\n",
    "            buttons=list([\n",
    "                dict(label=\"Linear Scale\", method=\"relayout\", args=[{\"yaxis.type\": \"linear\"}]),\n",
    "                dict(label=\"Log Scale\", method=\"relayout\", args=[{\"yaxis.type\": \"log\"}]),\n",
    "            ]),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüîç Key Insights:\")\n",
    "print(f\"  ‚Ä¢ Median Legitimate Amount: ${legitimate_amounts.median():.2f}\")\n",
    "print(f\"  ‚Ä¢ Median Fraud Amount: ${fraud_amounts.median():.2f}\")\n",
    "print(f\"  ‚Ä¢ Max Legitimate: ${legitimate_amounts.max():.2f}\")\n",
    "print(f\"  ‚Ä¢ Max Fraud: ${fraud_amounts.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix for key features\n",
    "# (Using only V1-V5 for clarity)\n",
    "features = ['Amount'] + [f'V{i}' for i in range(1, 6)] + ['Class']\n",
    "corr_matrix = df[features].corr()\n",
    "\n",
    "# Create heatmap\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=corr_matrix.values,\n",
    "    x=corr_matrix.columns,\n",
    "    y=corr_matrix.columns,\n",
    "    colorscale='RdBu',\n",
    "    zmid=0,\n",
    "    text=np.round(corr_matrix.values, 2),\n",
    "    texttemplate='%{text}',\n",
    "    textfont={\"size\": 10},\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Feature Correlation Heatmap',\n",
    "    height=500,\n",
    "    width=600\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Show correlations with fraud class\n",
    "fraud_corr = corr_matrix['Class'].sort_values(ascending=False)\n",
    "print(\"\\nüîç Top Features Correlated with Fraud:\")\n",
    "for feature, corr in fraud_corr[1:6].items():  # Skip Class itself\n",
    "    print(f\"  ‚Ä¢ {feature}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Time-Based Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Time column to datetime (if available)\n",
    "# For this dataset, we'll analyze without explicit time column\n",
    "# Instead, let's create sample time patterns\n",
    "\n",
    "# Analyze transaction patterns by amount ranges\n",
    "bins = [0, 10, 50, 100, 500, float('inf')]\n",
    "labels = ['<$10', '$10-50', '$50-100', '$100-500', '>$500']\n",
    "df['Amount_Range'] = pd.cut(df['Amount'], bins=bins, labels=labels)\n",
    "\n",
    "# Calculate fraud rate per amount range\n",
    "fraud_by_range = df.groupby('Amount_Range', observed=True).agg({\n",
    "    'Class': ['mean', 'count']\n",
    "}).reset_index()\n",
    "fraud_by_range.columns = ['Amount Range', 'Fraud Rate', 'Count']\n",
    "\n",
    "# Create bar chart\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add bars\n",
    "fig.add_trace(go.Bar(\n",
    "    x=fraud_by_range['Amount Range'],\n",
    "    y=fraud_by_range['Fraud Rate'] * 100,\n",
    "    marker_color='#FF6B6B',\n",
    "    text=fraud_by_range['Fraud Rate'].apply(lambda x: f\"{x*100:.2f}%\"),\n",
    "    textposition='outside',\n",
    "    name='Fraud Rate'\n",
    "))\n",
    "\n",
    "# Add count as secondary y-axis\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=fraud_by_range['Amount Range'],\n",
    "    y=fraud_by_range['Count'],\n",
    "    mode='lines+markers',\n",
    "    name='Transaction Count',\n",
    "    yaxis='y2'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Fraud Rate by Transaction Amount Range',\n",
    "    xaxis_title='Amount Range',\n",
    "    yaxis_title='Fraud Rate (%)',\n",
    "    yaxis2=dict(\n",
    "        title='Transaction Count',\n",
    "        overlaying='y',\n",
    "        side='right'\n",
    "    ),\n",
    "    height=500,\n",
    "    barmode='group'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüîç Key Insights:\")\n",
    "for _, row in fraud_by_range.iterrows():\n",
    "    print(f\"  ‚Ä¢ {row['Amount Range']}: {row['Fraud Rate']*100:.2f}% fraud ({row['Count']:,} transactions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. PCA Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data for PCA (use subset for speed)\n",
    "sample_df = df.sample(n=min(10000, len(df)), random_state=42)\n",
    "\n",
    "# Prepare features (V1-V28)\n",
    "feature_cols = [f'V{i}' for i in range(1, 29)]\n",
    "X = sample_df[feature_cols].values\n",
    "y = sample_df['Class'].values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Create scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add points for each class\n",
    "for class_val, class_name, color in [(0, 'Legitimate', '#4ECDC4'), (1, 'Fraud', '#FF6B6B')]:\n",
    "    mask = y == class_val\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=X_pca[mask, 0],\n",
    "        y=X_pca[mask, 1],\n",
    "        mode='markers',\n",
    "        name=class_name,\n",
    "        marker=dict(\n",
    "            size=5,\n",
    "            opacity=0.6,\n",
    "            color=color\n",
    "        ),\n",
    "        text=[f\"Class={class_val}\" for _ in range(sum(mask))]\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'PCA Visualization (Explained Variance: {pca.explained_variance_ratio_.sum()*100:.1f}%)',\n",
    "    xaxis_title='PC1',\n",
    "    yaxis_title='PC2',\n",
    "    height=600,\n",
    "    hovermode='closest'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(f\"\\nüîç PCA Results:\")\n",
    "print(f\"  ‚Ä¢ PC1 Explained Variance: {pca.explained_variance_ratio_[0]*100:.2f}%\")\n",
    "print(f\"  ‚Ä¢ PC2 Explained Variance: {pca.explained_variance_ratio_[1]*100:.2f}%\")\n",
    "print(f\"  ‚Ä¢ Total Explained Variance: {pca.explained_variance_ratio_.sum()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate key statistics\n",
    "stats = {\n",
    "    'Total Transactions': len(df),\n",
    "    'Fraud Cases': int(df['Class'].sum()),\n",
    "    'Fraud Rate': f\"{df['Class'].mean()*100:.3}%\",\n",
    "    'Avg Transaction Amount': f\"${df['Amount'].mean():.2f}\",\n",
    "    'Median Transaction Amount': f\"${df['Amount'].median():.2f}\",\n",
    "    'Max Transaction Amount': f\"${df['Amount'].max():.2f}\",\n",
    "    'Features (V1-V28)': 28,\n",
    "}\n",
    "\n",
    "# Display as formatted table\n",
    "print(\"=\"*60)\n",
    "print(\"FRAUD DETECTION DATASET - SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key:.<40} {value}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Takeaways\n",
    "\n",
    "### Data Characteristics:\n",
    "1. **Severe Class Imbalance**: Only 0.173% fraud cases (typical for fraud detection)\n",
    "2. **Anonymized Features**: V1-V28 are PCA-transformed (original features hidden)\n",
    "3. **Amount Distribution**: Highly skewed, most transactions are small\n",
    "\n",
    "### Challenges for Machine Learning:\n",
    "- ‚ùå **Imbalanced Data**: Models biased toward majority class\n",
    "- ‚ùå **Feature Anonymization**: Hard to interpret feature importance\n",
    "- ‚ö†Ô∏è **Overlap**: Fraud and legitimate transactions overlap in feature space\n",
    "\n",
    "### Solutions:\n",
    "- ‚úÖ Use resampling techniques (SMOTE, oversampling)\n",
    "- ‚úÖ Apply class weights during training\n",
    "- ‚úÖ Use anomaly detection algorithms\n",
    "- ‚úÖ Ensemble methods for better performance\n",
    "\n",
    "### Next Steps:\n",
    "‚Üí **Day 2**: Classification Benchmark (handle imbalance)\n",
    "‚Üí **Day 3**: Feature Engineering (create better features)\n",
    "\n",
    "---\n",
    "\n",
    "**üìÅ Project Location**: `01_fraud_detection_core/fraud_detection_eda_dashboard/`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
