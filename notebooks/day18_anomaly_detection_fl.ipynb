{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 18: Anomaly Detection for FL Security\n",
    "\n",
    "**Real-Time Detection of Malicious Client Updates**\n",
    "\n",
    "## Overview\n",
    "- **Goal**: Detect malicious client updates in real-time\n",
    "- **Methods**: L2 norm, cosine similarity, clustering, autoencoders\n",
    "- **Deployment**: Server-side monitoring system\n",
    "\n",
    "## What You'll Learn\n",
    "1. **Update Anomalies**: What makes an update suspicious?\n",
    "2. **Detection Methods**: L2 norm, cosine similarity, KL divergence\n",
    "3. **Threshold Selection**: Statistical approaches\n",
    "4. **Ensemble Detection**: Combining multiple methods\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What Makes an Update Anomalous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"\"\"\n",
    "ANOMALOUS UPDATE CHARACTERISTICS:\n",
    "\n",
    "1. LARGE L2 NORM\n",
    "   ‚Ä¢ Normal: ~0.1-1.0\n",
    "   ‚Ä¢ Anomalous: >10.0\n",
    "   ‚Ä¢ Detection: Compare to historical distribution\n",
    "\n",
    "2. WRONG DIRECTION (Cosine Similarity)\n",
    "   ‚Ä¢ Normal: Similar to other updates (cosine > 0.5)\n",
    "   ‚Ä¢ Anomalous: Opposite direction (cosine < -0.5)\n",
    "   ‚Ä¢ Detection: Angle to mean update\n",
    "\n",
    "3. STATISTICAL OUTLIER\n",
    "   ‚Ä¢ Normal: Within 2-3 standard deviations\n",
    "   ‚Ä¢ Anomalous: Beyond 3 standard deviations\n",
    "   ‚Ä¢ Detection: Z-score, IQR, isolation forest\n",
    "\n",
    "4. RARE PATTERN\n",
    "   ‚Ä¢ Normal: Follows expected distribution\n",
    "   ‚Ä¢ Anomalous: Unusual pattern\n",
    "   ‚Ä¢ Detection: Autoencoder, one-class SVM\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. L2 Norm Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_norm_detector(updates, threshold=None, z_score_threshold=3.0):\n",
    "    \"\"\"\n",
    "    Detect anomalies using L2 norm.\n",
    "    \n",
    "    Args:\n",
    "        updates: List of weight updates\n",
    "        threshold: Fixed threshold (if None, use statistical)\n",
    "        z_score_threshold: Z-score threshold for statistical detection\n",
    "        \n",
    "    Returns:\n",
    "        anomalies: List of booleans (True if anomalous)\n",
    "        norms: L2 norms for all updates\n",
    "    \"\"\"\n",
    "    # Compute L2 norms\n",
    "    norms = [np.linalg.norm(u) for u in updates]\n",
    "    \n",
    "    if threshold is not None:\n",
    "        # Fixed threshold\n",
    "        anomalies = [norm > threshold for norm in norms]\n",
    "    else:\n",
    "        # Statistical threshold (z-score)\n",
    "        mean_norm = np.mean(norms)\n",
    "        std_norm = np.std(norms)\n",
    "        z_scores = [(norm - mean_norm) / (std_norm + 1e-10) for norm in norms]\n",
    "        anomalies = [abs(z) > z_score_threshold for z in z_scores]\n",
    "    \n",
    "    return anomalies, norms\n",
    "\n",
    "# Test with mixed honest/malicious updates\n",
    "np.random.seed(42)\n",
    "honest_updates = [np.random.randn(100) * 0.1 for _ in range(9)]\n",
    "malicious_updates = [\n",
    "    np.random.randn(100) * 5,  # Large norm\n",
    "    np.random.randn(100) * 0.1 * 50  # Scaled attack\n",
    "]\n",
    "all_updates = honest_updates + malicious_updates\n",
    "\n",
    "# Detect\n",
    "anomalies, norms = l2_norm_detector(all_updates, z_score_threshold=2.5)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['green' if not a else 'red' for a in anomalies]\n",
    "plt.bar(range(len(norms)), norms, color=colors, alpha=0.7)\n",
    "plt.axhline(y=np.mean(norms[:9]), color='blue', linestyle='--', label='Honest mean')\n",
    "plt.xlabel('Client ID', fontsize=12)\n",
    "plt.ylabel('L2 Norm', fontsize=12)\n",
    "plt.title('L2 Norm Anomaly Detection\\n(Green=Honest, Red=Anomalous)', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Detected {sum(anomalies)} anomalies out of {len(all_updates)} clients\")\n",
    "print(f\"Malicious clients detected: {sum(anomalies[-2:])}/2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cosine Similarity Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_detector(updates, threshold=-0.5):\n",
    "    \"\"\"\n",
    "    Detect anomalies using cosine similarity to mean update.\n",
    "    \n",
    "    Args:\n",
    "        updates: List of weight updates\n",
    "        threshold: Cosine similarity threshold (below = anomalous)\n",
    "        \n",
    "    Returns:\n",
    "        anomalies: List of booleans\n",
    "        similarities: Cosine similarities\n",
    "    \"\"\"\n",
    "    # Compute mean direction\n",
    "    mean_update = np.mean(updates, axis=0)\n",
    "    mean_update /= (np.linalg.norm(mean_update) + 1e-10)\n",
    "    \n",
    "    # Compute cosine similarities\n",
    "    similarities = []\n",
    "    for update in updates:\n",
    "        update_norm = update / (np.linalg.norm(update) + 1e-10)\n",
    "        sim = np.dot(mean_update, update_norm)\n",
    "        similarities.append(sim)\n",
    "    \n",
    "    # Detect anomalies (low similarity = wrong direction)\n",
    "    anomalies = [sim < threshold for sim in similarities]\n",
    "    \n",
    "    return anomalies, similarities\n",
    "\n",
    "# Test with sign-flipping attack\n",
    "np.random.seed(42)\n",
    "honest_updates = [np.random.randn(50) * 0.1 + 1 for _ in range(8)]\n",
    "sign_flip_attack = [-honest_updates[0]]  # Opposite direction\n",
    "all_updates = honest_updates + sign_flip_attack\n",
    "\n",
    "# Detect\n",
    "anomalies, similarities = cosine_similarity_detector(all_updates, threshold=-0.3)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['green' if not a else 'red' for a in anomalies]\n",
    "plt.bar(range(len(similarities)), similarities, color=colors, alpha=0.7)\n",
    "plt.axhline(y=-0.3, color='orange', linestyle='--', label='Threshold')\n",
    "plt.xlabel('Client ID', fontsize=12)\n",
    "plt.ylabel('Cosine Similarity to Mean', fontsize=12)\n",
    "plt.title('Cosine Similarity Anomaly Detection\\n(Red=Opposite Direction)', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.ylim(-1.1, 1.1)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Detected {sum(anomalies)} sign-flipping attack(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ensemble Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_anomaly_detector(updates):\n",
    "    \"\"\"\n",
    "    Ensemble multiple detection methods.\n",
    "    \n",
    "    Methods:\n",
    "    1. L2 norm (statistical)\n",
    "    2. Cosine similarity\n",
    "    3. Euclidean distance from mean\n",
    "    \n",
    "    Returns:\n",
    "        anomalies: List of booleans (True if any method flags)\n",
    "        scores: Dict of anomaly scores per method\n",
    "    \"\"\"\n",
    "    # Method 1: L2 norm z-score\n",
    "    _, l2_anomalies, _ = l2_norm_detector(updates, z_score_threshold=2.5)\n",
    "    \n",
    "    # Method 2: Cosine similarity\n",
    "    cos_anomalies, _ = cosine_similarity_detector(updates, threshold=-0.5)\n",
    "    \n",
    "    # Method 3: Euclidean distance\n",
    "    mean_update = np.mean(updates, axis=0)\n",
    "    distances = [np.linalg.norm(u - mean_update) for u in updates]\n",
    "    mean_dist = np.mean(distances)\n",
    "    std_dist = np.std(distances)\n",
    "    z_scores = [(d - mean_dist) / (std_dist + 1e-10) for d in distances]\n",
    "    dist_anomalies = [abs(z) > 2.5 for z in z_scores]\n",
    "    \n",
    "    # Combine (OR logic: flag if any method detects)\n",
    "    anomalies = [\n",
    "        l2 or cos or dist\n",
    "        for l2, cos, dist in zip(l2_anomalies, cos_anomalies, dist_anomalies)\n",
    "    ]\n",
    "    \n",
    "    scores = {\n",
    "        'l2_anomaly': l2_anomalies,\n",
    "        'cosine_anomaly': cos_anomalies,\n",
    "        'distance_anomaly': dist_anomalies,\n",
    "        'ensemble_anomaly': anomalies\n",
    "    }\n",
    "    \n",
    "    return anomalies, scores\n",
    "\n",
    "# Test ensemble\n",
    "np.random.seed(42)\n",
    "updates = [\n",
    "    np.random.randn(50) * 0.1 + 1 for _ in range(7)  # Honest\n",
    "] + [\n",
    "    np.random.randn(50) * 5,                   # Large norm\n",
    "    -updates[0] * 2,                           # Sign flip\n",
    "    np.random.randn(50) * 0.1 + 5             # Far from mean\n",
    "]\n",
    "\n",
    "anomalies, scores = ensemble_anomaly_detector(updates)\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame({\n",
    "    'Client': range(len(updates)),\n",
    "    'L2 Anomaly': scores['l2_anomaly'],\n",
    "    'Cosine Anomaly': scores['cosine_anomaly'],\n",
    "    'Distance Anomaly': scores['distance_anomaly'],\n",
    "    'ENSEMBLE (Any)': scores['ensemble_anomaly']\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENSEMBLE ANOMALY DETECTION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(results_df.to_string(index=False))\n",
    "print(f\"\\nTotal anomalies detected: {sum(anomalies)}/{len(updates)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "\n",
    "ANOMALY DETECTION SUMMARY:\n",
    "\n",
    "Detection Methods:\n",
    "\n",
    "1. L2 NORM (Magnitude-based)\n",
    "   ‚Ä¢ Detects: Gradient scaling, large updates\n",
    "   ‚Ä¢ Threshold: Statistical (z-score) or fixed\n",
    "   ‚Ä¢ Pros: Simple, fast, effective for scaling attacks\n",
    "   ‚Ä¢ Cons: Misses same-magnitude attacks (sign flip)\n",
    "\n",
    "2. COSINE SIMILARITY (Direction-based)\n",
    "   ‚Ä¢ Detects: Sign flipping, wrong direction\n",
    "   ‚Ä¢ Threshold: < -0.5 (opposite direction)\n",
    "   ‚Ä¢ Pros: Detects subtle direction attacks\n",
    "   ‚Ä¢ Cons: Misses scaling attacks (same direction)\n",
    "\n",
    "3. EUCLIDEAN DISTANCE\n",
    "   ‚Ä¢ Detects: Any deviation from group norm\n",
    "   ‚Ä¢ Threshold: Z-score > 2.5\n",
    "   ‚Ä¢ Pros: General-purpose\n",
    "   ‚Ä¢ Cons: Less specific\n",
    "\n",
    "4. ENSEMBLE (Combine All)\n",
    "   ‚Ä¢ Detects: All attack types\n",
    "   ‚Ä¢ Logic: OR (flag if any method detects)\n",
    "   ‚Ä¢ Pros: Highest detection rate\n",
    "   ‚Ä¢ Cons: Higher false positive rate\n",
    "\n",
    "Deployment Considerations:\n",
    "  ‚Ä¢ Run on server after receiving all client updates\n",
    "  ‚Ä¢ Block detected anomalies before aggregation\n",
    "  ‚Ä¢ Log detections for audit trail\n",
    "  ‚Ä¢ Tune thresholds based on historical data\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "### Anomaly Detection for FL Security:\n",
    "\n",
    "**Key Insight:**\n",
    "- Malicious updates look DIFFERENT from honest ones\n",
    "- Multiple dimensions: magnitude, direction, distribution\n",
    "- Ensemble detection catches all attack types\n",
    "\n",
    "**Detection Pipeline:**\n",
    "1. Client sends update ‚Üí Server\n",
    "2. Server collects all updates (wait for all or timeout)\n",
    "3. Run anomaly detection (L2, cosine, distance)\n",
    "4. Flag anomalous clients\n",
    "5. Aggregate only honest updates (Krum, trimmed mean)\n",
    "\n",
    "**Best Practices:**\n",
    "- Use ensemble detection (multiple methods)\n",
    "- Tune thresholds on validation data\n",
    "- Log detections for monitoring\n",
    "- Combine with robust aggregation (Day 17)\n",
    "\n",
    "**Limitations:**\n",
    "- Sophisticated attacks can evade detection\n",
    "- Sybil attacks can overwhelm (use FoolsGold, Day 19)\n",
    "- False positives reject honest clients\n",
    "\n",
    "### Next Steps:\n",
    "‚Üí **Day 19**: FoolsGold (Sybil-resistant aggregation)\n",
    "\n",
    "---\n",
    "\n",
    "**üìÅ Project Location**: `04_defensive_techniques/anomaly_detection_system/`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
