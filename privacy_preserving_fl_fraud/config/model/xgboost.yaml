# XGBoost Model Configuration

model:
  type: xgboost
  learning_rate: 0.1
  max_depth: 6
  n_estimators: 100
  min_child_weight: 1
  subsample: 0.8
  colsample_bytree: 0.8
  gamma: 0
  reg_alpha: 0
  reg_lambda: 1
  scale_pos_weight: 1  # Auto-computed for imbalanced data

  # Training
  early_stopping_rounds: 10
  eval_metric: logloss
  objective: binary:logistic

  # Loss function (for consistency with neural models)
  loss_function: cross_entropy
